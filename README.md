# Image Classification and Captioning Project

This project performs image classification and captioning using two powerful models:
- **BLIP** (Bootstrapping Language-Image Pretraining) for generating captions.
- **CLIP** (Contrastive Language-Image Pretraining) for zero-shot image classification.

## Features

- **Image Captioning**: Generates detailed captions for images using the BLIP model.
- **Zero-shot Image Classification**: Matches images to provided text descriptions using the CLIP model.
